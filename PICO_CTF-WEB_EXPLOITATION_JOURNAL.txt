PICO_CTF-CHALLENGES_JOURNAL_WALKTHROUGH_4_RFERENCES
WEB-EXPLOITATION
1. GET aHEAD - We used BurpSuite to Intercept the websites GET request. Which we were able to change the GET request to HEAD value, But we had to enable the option to 'Intercept Server Responses'
ORIGINAL VALUE = 
GET /index.php? HTTP/1.1

Host: mercury.picoctf.net:53554

CHANGED VALUE = 
HEAD /index.php? HTTP/1.1

Host: mercury.picoctf.net:53554

WHAT I LEARNED: You can intercept the web traffic using BurpSuite and change the requests to whichever value you find suitable in order to acquire other sections of the web pages.

2. Cookies - This tested us on the ability to change the cookies value in order to find the flag on the stored cookies session. 

WHAT I LEARNED : I learned that the ability to modify the cookies value on the web browser gave the person the ability to access other options of the websites.

3. Insp3ct0r - We inspected the HTML, CSS and JS code base of the websites in order to acquire the flag.

WHAT I LEARNED : You can be able to change learn alot about websites by just inspecting elements of a web page.

4. Scavenger Hunt - We still were able to find clues about other sections of a web page from inspecting the HTML, CSS and JS code base of the websites. But other clues included = 

APACHE SERVER - if you navigate to the .htaccess directory of the websites. YOu can still access other section of the page.

MAC WEBSITES INFO - I also learned that navigating to the .DS_Store of the website that reveal more information of a web application. But more importantly on MAC enabled websites.

5. More Cookies - This tested if you are able to recognize that Base64 encrypted cookies can be able to be cracked/decrypted using the bitflip kind of solution. Mike on Tech, a YT channel wrote a script that can be able to bit flip the decrypt the Homomophonic encrpyted cookie session. It's found in github : https://github.com/kevinnevs/PICO_CTF/blob/main/AES_CBC_For_Byte_Flipping.py . The crpytography used is AES and as well CBC (Cookies Can Be Modified Client-side )

WHAT I LEARNED : It's possible to know more about a web application, if you study further the cookies stored on the client side. Even though it is encrpyted, it's still possible to decipher and further crack out more about the web application's weak point.

5. Where are the robots - This challenged was solved by finding out what was stored in the Google non-indexed web sections of the page, which was an old way of hiding contents of the page that you would not want to be indexed.

WHAT I LEARNED : You can know more about hidden web contents of a page, if you navigate to the 'robots.txt' section of the web application. This usually contains web information of non-indexed web pages that the Web owner wouldn't want to be indexed.

6. Logon - This challenged was to exploit the weakness of a login page that allowed only a specific user can login with a password. Weirdly enough, the client side cookie session only stored three cookies. Namely 'admin' , 'username' , and  'password' with the admin value set to False. The weakness was, once you are logged in with any user, you can modify the 'admin' cookie name value to True. Which will allow you to access the page as a privileged user.

WHAT I LEARNED : A web application vulnerability can be set on the login page form, with the client side cookie sesssion's are modifiable and once modified, you can be able to access the admin section's of a page, or increase the user's privilege. 

7. dont-use-client-side - This challenged tested in finding out if you can see whether passwords of a web application are stored at the client side. Which is the case, just by going through the Javascript function (from going through the web application element) that checks and verifies if the password substring is correct. Then you can be able to exploit the password substring one by one, which results out to be a flag.

WHAT I LEARNED : A web applicaitions vulnerability can be set out by storing password substrings from the client side, which should not be the case. A person can identify the password, by going through the elements and finding out the correct substring used.

8. It is my birthday - This challenged tested on knowing that sometimes files do have the same md5 hash, this is a vulnerability area for file's that can be uploaded on a website. With this possible, you can exploit further the web server by creating two files with the same md5 hash. One can be a 'good' file, the other can be an 'evil' file, that can allow a person to run a special script/ ransomware that will exploit a weakness in the system. We can learn further from this website : https://www.mathstat.dal.ca/~selinger/md5collision/

WHAT I LEARNED : Alway's ensure that your web server's accept unique/same files with a unique md5 hash, if an original file that can't be verified with it's unique md5 hash. It can be a weakness point that can be further exploited.

9. Who are you? - This challenge tested on the knowledge of using 'wget' command on the terminal to access website elements. If you accessed the web application on the browser. The browser will redirect you to a wrong web application. Hence, one had to formulate a wget script on the terminal. That had specific options in order to find the flag/ download the right index.html page that contained the element, the script wget was looking like this : 

wget http://mercury.picoctf.net:39114/ -U PicoBrowser --header='Referer: http://mercury.picoctf.net:39114' --header="Date: 2018" --header="X-Forwarded-For: 88.80.28.16" --header="DNT: dnt" --header="Accept-language: sv"

A. wget http://mercury.picoctf.net:39144 -> This is for accessing the web url and it's port.
B. -U -> Thi is a wget option flag to specify the specific arguments passed in order to access elements for the web application.
C. PicoBrowser -> you have to access the web application inside the PicoBrowser.
D. --header='Referer: http://mercury.picoctf.net:39114 -> You have to specific the web url, after passing the PicoBrowser argument.
E. --header='Date: 2018" -> This header is to specify the website date version.
F. --header='X-Forwarded-For: 88.80.28.16' -> This header is to access the website using a Sweden IP address
G. --header='Dnt: dnt' -> This header is to hide/ avoid being tracked.
H. --header='Accept-language: sv' -> This header is to specify the language to be used for the web application version.

WHAT I LEARNED: You can access website application with hidden configuration and modify the arguments using wget. It can be a powerful tool, as you can download hidden  information based on location, language, date or other formats that are not specified when accessing the website on a normal browser.

10. Login - This challenge tested in finding vulnerability in a login page websise. The website with this url: https://login.mars.picoctf.net/ had a weakpoint. After analyzing and inspecting the website login html element. I saw a script source of index.js, which is used to validate and ensure the login information used is correct. But to my surprise, the crpytography used to encrpt the username field used a Base64 encoding, which contained the flag.

WHAT I LEARNED: When building a web application, always ensure not to encrypt information from the client side. Even if encrpyting the information is necessary, using the Base64 encoding crpytography is easily encoded. Which can give the person accessing the website, an upperhand to view further information.

11. Includes - This challenge involved inspecting the source elements used for the website : http://saturn.picoctf.net:59300/ . The clue was to find the secondary source files that contained the flags. One was found in the css stylesheet file style.css, and the script file script.js

WHAT I LEARNED : Always inspect the website secondary source files to find weak points/vulnerability in a web application.

12. Inspect HTML - This challenge involves inspecting the source elements as well. On the website: http://saturn.picoctf.net:49386/. The flag was present in the HTML file, with the flag commented.

WHAT I LEARNED: More emphasis was made on inspecting the source files of the web application to find vulnerability. More especially on the primary source file with HTML.

13. Local Authority - This challenge involved finding vulnerability when verifying the identify of the username and the password used in a web application. After inspecting the login page. The client side did not unveil the js script used to verify the username and password. But this was revealed, once you key in a wrong username or password, it redirects you to a 'Log In Failed' page. Which when you inspect, you will find a secure.js script source file that verifies the username and password used in the website. Unfortunately, the secure.js file openly reveals what is to be checked using the below if statement : 

function checkPassword(username, password)
{
  if( username === 'admin' && password === 'strongPassword098765' )
  {
    return true;
  }
  else
  {
    return false;
  }
}

As indicated, the credentials used are in plain site.

WHAT I LEARNED : Never redirect a web application that has Unfortunately used bad credentials to a verifying script and it will be reveled on the client side. This is bad coding practice, which will reveal the credentials used to log into the web application.